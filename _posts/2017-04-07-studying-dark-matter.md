---
title: "Studying dark matter"
summary: "“The Nordic Data Grid Facility works so well that it has become one of the most efficient of all the Tier 1 facilities,” says Professor Farid Ould-Sadaa at the University of Oslo. He analyses data from CERN and the Large Hadron Collider  in a quest to solve one of the largest remaining mysteries in science: the nature of dark matter."
photo: "/assets/images/news/farid-ould-saada.jpg"
---

# Studying dark matter

**“The Nordic Data Grid Facility works so well that it has become one of the most efficient of all the Tier 1 facilities,” says Professor Farid Ould-Sadaa at the University of Oslo. He analyses data from CERN and the Large Hadron Collider  in a quest to solve one of the largest remaining mysteries in science: the nature of dark matter.**

<a href="{% include baseurl %}/assets/images/news/farid-ould-saada.jpg">
<img class="smallpic" src="{% include baseurl %}/assets/images/news/farid-ould-saada.jpg">
</a>

Professor Ould-Sadaa explains that dark matter is a mystery in both particle physics and astrophysics. We know from observations that the universe must contain a type of matter that does not emit or interact with electromagnetic radiation, so it must be different from the ordinary matter that surrounds us.

“We are trying to solve this mystery by looking at it from all possible angles, and one of the angles involves using the Large Hadron Collider (LHC). We are basically trying to produce dark matter by recreating the conditions that existed in the universe shortly after the Big Bang. Because we know that dark matter – whatever it is – had to be there from the start,” he explains.

Professor Ould-Sadaa is involved in the Atlas experiment, which is one of the two general-purpose detectors at the LHC. The giant detector weighs 7 000 tonnes and investigates a wide range of physics, from the search for the Higgs boson to extra dimensions and particles that could make up dark matter.

“We realised around the year 2000 that the amount of data would become a problem. When the LHC is running, we have a collision between particles every 25 nanoseconds, and each collision generates an enormous amount of data. The Worldwide LHC Computing Grid handles hundreds of petabytes (1015 bytes) per year, and we expect a 10-to-100-fold increase in the years to come,” he says.

The scientists at CERN soon realised that they would need a system for distributed computing and arrived at the present tier structure after much deliberation. Professor Ould-Sadaa is very happy with the Nordic Data Grid Tier 1 Facility, which in his opinion functions better than the other Tier 1 facilities around the world. He says that the successful outcome is due in large part to the “middleware” that was developed in the NorduGrid collaboration and to the close cooperation between physicists, computer scientists and system administrators.

“It was necessary to have a critical mass of scientists and other experts in order to establish a Tier 1 facility, and none of the Nordic countries had the necessary resources on their own. But we reached the level of critical mass when we decided to collaborate at the Nordic level,” Professor Ould-Sadaa concludes.

Have a look at our article [The smartest storage for the world’s largest data volumes](../../../../2017/04/07/the-smartest-storage-for-the-worlds-largest-data-volumes) to read more about the Nordic Data Grid Facility.
